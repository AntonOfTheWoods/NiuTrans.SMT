############################################
### NiuTrans decoder configuration file  ###
###   hierarchical phrase-based system   ###
###              2011-07-01              ###
############################################

#>>>>>>>>>>>>>>>>>>>>>>
#>>> runtime resource tables

# language model
param="Ngram-LanguageModel-File"     value="../work/lm/lm.trie.data"

# target-side vocabulary
param="Target-Vocab-File"            value="../work/lm/lm.vocab"

# phrase translation model
param="SCFG-Rule-Set"                value="../work/model.hierarchy/hierarchy.rule.table.filterDev"

# Punctuations specified (sample file is in utf8.).
# Of course, users can modify/change this file as needed.
param="Punct-Vocab-File"             value="../resource/punct.utf8.txt"

#>>>>>>>>>>>>>>>>>>>>>>
#>>> runtime parameters

# number of MERT iterations
param="nround"                       value="12"

# order of n-gram language model
param="ngram"                        value="5"

# maximum phrase length
param="maxphraselength"              value="7"

# use punctuation pruning (1) or not (0)
param="usepuncpruning"               value="1"

# use cube-pruning (1) or not (0)
param="usecubepruning"               value="1"

# use maxent reordering model (1) or not (0)
param="use-me-reorder"               value="1"

# use msd reordering model (1) or not (0)
param="use-msd-reorder"              value="1"

# number of threads
param="nthread"                      value="8"

# how many translations are dumped
param="nbest"                        value="30"

# output OOV words
param="outputoov"                    value="0"

# output source words that are explicitly deleted
param="outputnull"                   value="0"

# beam size (or beam width)
param="beamsize"                     value="50"

# beam scale. This parameter controls the number of hypotheses
# that are computed in decoding.
# e.g., beamscale=3 means we search over 3 * beamsize hyphotheses
param="beamscale"                    value="1"

# number of references of dev. set
param="nref"                         value="4"

# allow null-translation (i.e. word-deletion)
param="usenulltrans"                 value="0"

# allow sequence of null-translations
param="snulltrans"                   value="1"

# normalize output (1) or not (0)
param="normalizeoutput"              value="0"

# distortion limit
param="maxdd"                        value="10"

# char-based BLEU_SBP
param="charmert"                     value="1"
param="utf8"                         value="1"
param="bleungram"                    value="5"

#>>>>>>>>>>>>>>>>>>>>>>
#>>> model parameters

# features used
#  0: n-gram language model
#  1: number of target-words
#  2: Pr(e|f). f->e translation probablilty.
#  3: Lex(e|f). f->e lexical weight
#  4: Pr(f|e). e->f translation probablilty.
#  5: Lex(f|e). e->f lexical weight
#  6: number of rules
#  7: number of bi-lex links (not fired in current version)
#  8: number of NULL-translation (i.e. word deletion)
#  9: number of phrasal rules
# 10: number of glue rules
# 11: <UNDEFINED>
# 12: <UNDEFINED>
# 13: <UNDEFINED>
# 14: <UNDEFINED>
# 15: <UNDEFINED>
# 16: <UNDEFINED>

# feature weights
param="weights"                      value="1.7695 1.8979 1.2627 0.4000 0.6074 0.2598 -0.0365 0.5800 -0.0600 -2.9667 1.8709 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000"

# bound the feature weight in MERT
# e.g. the first number "-3:7" means that the first feature weight ranges in [-3, 7]
param="ranges"                       value="-3:7 -1:3 0:3 0:0.4 0:3 0:0.4 -3:3 -3:3 -3:0 -3:3 -3:3 0:0 0:0 0:0 0:0 0:0 0:0"

# fix a dimention (1) or not (0)
param="fixedfs"                      value="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0"
param="weights"                      value="1.79125 1.8879 1.2586 0.36345 0.48365 0.3631 -0.80555 0.6 -0.145 -2.23495 1.4811 0 0 0 0 0 0"